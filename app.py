import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
import datetime

# --- CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(
    page_title="VI Trucks JST - IA Analytics",
    page_icon="üß†",
    layout="wide"
)

# --- ESTILOS CSS PERSONALIZADOS ---
st.markdown("""
    <style>
    .metric-card { background-color: #f9f9f9; border-left: 5px solid #4CAF50; padding: 15px; border-radius: 5px; box-shadow: 2px 2px 5px rgba(0,0,0,0.1); }
    </style>
    """, unsafe_allow_html=True)

# --- ENCABEZADO ---
st.title("üß† VI Trucks JST: Plataforma de Inteligencia Artificial")
st.markdown("**Cliente:** CPG Chile | **M√≥dulo:** Analytics Avanzado (Clustering & Predicci√≥n) | **Versi√≥n:** 3.1 (Proyecci√≥n Mensual)")

# --- 1. M√ìDULO DE INGESTA Y ETL (EXTRACT, TRANSFORM, LOAD) ---
@st.cache_data
def cargar_y_limpiar_datos():
    try:
        # EXTRACT: Carga de datos crudos
        df = pd.read_csv('simulacion_piloto_60dias_CPG.csv')
        
        # TRANSFORM: Limpieza y Casteo de Tipos
        # Convertir fechas a objetos datetime reales
        df['Fecha Ingreso'] = pd.to_datetime(df['Fecha Ingreso'])
        # Imputaci√≥n de nulos (si existieran) con 0 o la media
        df.fillna(0, inplace=True)
        
        return df
    except FileNotFoundError:
        return None

df = cargar_y_limpiar_datos()

if df is None:
    st.error("‚ö†Ô∏è ERROR CR√çTICO: No se encontr√≥ el archivo 'simulacion_piloto_60dias_CPG.csv'. Aseg√∫rese de que est√© en la misma carpeta.")
else:
    # --- BARRA LATERAL (FILTROS GLOBALES) ---
    st.sidebar.header("üîç Filtros de Operaci√≥n")
    
    # Filtro de Fechas Din√°mico
    min_date, max_date = df['Fecha Ingreso'].min(), df['Fecha Ingreso'].max()
    fechas = st.sidebar.date_input("Rango de An√°lisis", (min_date, max_date), min_value=min_date, max_value=max_date)
    
    # Filtro de Materiales
    todos_materiales = df['Material (IA Class)'].unique()
    materiales_sel = st.sidebar.multiselect("Tipo de Material", todos_materiales, default=todos_materiales)
    
    # Filtro de Empresas
    todas_empresas = df['Empresa'].unique()
    empresas_sel = st.sidebar.multiselect("Empresa Transportista", todas_empresas, default=todas_empresas)

    # APLICACI√ìN DE FILTROS (M√ÅSCARA)
    if isinstance(fechas, tuple) and len(fechas) == 2:
        mask = (
            (df['Fecha Ingreso'].dt.date >= fechas[0]) & 
            (df['Fecha Ingreso'].dt.date <= fechas[1]) & 
            (df['Material (IA Class)'].isin(materiales_sel)) &
            (df['Empresa'].isin(empresas_sel))
        )
        df_filtered = df[mask].copy()
    else:
        df_filtered = df.copy()

    # --- PESTA√ëAS DE NAVEGACI√ìN ---
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Dashboard Operativo", "üßπ Calidad de Datos (ETL)", "ü§ñ Clustering (IA)", "üîÆ Predicciones (30 D√≠as)"])

    # ==========================================
    # TAB 1: DASHBOARD OPERATIVO
    # ==========================================
    with tab1:
        st.subheader("Estado Actual de la Operaci√≥n (KPIs)")
        
        if df_filtered.empty:
            st.warning("No hay datos para los filtros seleccionados.")
        else:
            col1, col2, col3, col4 = st.columns(4)
            
            # C√°lculo de m√©tricas
            prec_media = df_filtered['Precisi√≥n (%)'].mean()
            vol_total = df_filtered['Vol. IA (m¬≥)'].sum()
            camiones = len(df_filtered)
            fallos = len(df_filtered[df_filtered['Precisi√≥n (%)'] < 90])
            tasa_fallos = (fallos / camiones) * 100 if camiones > 0 else 0

            # Despliegue de m√©tricas
            col1.metric("Precisi√≥n Global", f"{prec_media:.2f}%", delta="Meta > 90%")
            col2.metric("Volumen Procesado", f"{vol_total:,.0f} m¬≥")
            col3.metric("Flujo de Camiones", f"{camiones}", delta="Unidades")
            col4.metric("Tasa de Error", f"{tasa_fallos:.1f}%", delta_color="inverse")
            
            st.divider()

            # Gr√°ficos Operativos
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("##### Evoluci√≥n Diaria de Precisi√≥n")
                daily_acc = df_filtered.groupby('Fecha Ingreso')['Precisi√≥n (%)'].mean().reset_index()
                fig_evo = plt.figure(figsize=(10, 4))
                sns.lineplot(data=daily_acc, x='Fecha Ingreso', y='Precisi√≥n (%)', marker='o', color='green')
                plt.axhline(90, color='red', linestyle='--', label='Meta 90%')
                plt.grid(True, alpha=0.3)
                st.pyplot(fig_evo)
            
            with c2:
                st.markdown("##### Ranking de Precisi√≥n por Empresa")
                ranking = df_filtered.groupby('Empresa')['Precisi√≥n (%)'].mean().sort_values().reset_index()
                fig_rank = plt.figure(figsize=(10, 4))
                sns.barplot(data=ranking, x='Precisi√≥n (%)', y='Empresa', palette='viridis')
                plt.axvline(90, color='red', linestyle='--')
                st.pyplot(fig_rank)

    # ==========================================
    # TAB 2: CALIDAD DE DATOS (ETL AUDIT)
    # ==========================================
    with tab2:
        st.subheader("üßπ Auditor√≠a de Calidad de Datos (Data Health)")
        st.info("Validaci√≥n t√©cnica de integridad de los datos antes del procesamiento IA.")
        
        col_a, col_b = st.columns(2)
        with col_a:
            st.markdown("#### 1. Integridad de Datos (Nulos)")
            nulos = df_filtered.isnull().sum()
            if nulos.sum() == 0:
                st.success("‚úÖ INTEGRIDAD OK: No se detectaron valores nulos.")
                st.dataframe(nulos, width=400)
            else:
                st.error(f"‚ö†Ô∏è ALERTA: Se detectaron {nulos.sum()} valores perdidos.")
                st.dataframe(nulos[nulos > 0])
        
        with col_b:
            st.markdown("#### 2. Estad√≠stica Descriptiva")
            st.dataframe(df_filtered[['Vol. Declarado (m¬≥)', 'Vol. IA (m¬≥)', 'Precisi√≥n (%)']].describe())

    # ==========================================
    # TAB 3: CLUSTERING (APRENDIZAJE NO SUPERVISADO)
    # ==========================================
    with tab3:
        st.subheader("ü§ñ Segmentaci√≥n Inteligente de Camiones")
        st.markdown("Algoritmo **K-Means** para agrupar camiones por comportamiento (Precisi√≥n vs Contaminaci√≥n).")

        if len(df_filtered) > 10:
            # Scaling
            X = df_filtered[['Precisi√≥n (%)', 'Contaminaci√≥n (%)']].copy()
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)

            # Selector de K
            k = st.slider("N√∫mero de Grupos (K)", 2, 5, 3)
            
            # Modelo K-Means
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            df_filtered['Cluster'] = kmeans.fit_predict(X_scaled)
            
            # Visualizaci√≥n
            col_k1, col_k2 = st.columns([3, 1])
            with col_k1:
                fig_k, ax_k = plt.subplots(figsize=(10, 6))
                sns.scatterplot(data=df_filtered, x='Precisi√≥n (%)', y='Contaminaci√≥n (%)', 
                                hue='Cluster', palette='deep', s=100, style='Material (IA Class)', ax=ax_k)
                plt.title(f"Segmentaci√≥n de la Flota en {k} Perfiles")
                st.pyplot(fig_k)
            
            with col_k2:
                st.markdown("#### Perfiles Identificados")
                for i in range(k):
                    cluster_data = df_filtered[df_filtered['Cluster'] == i]
                    p_mean = cluster_data['Precisi√≥n (%)'].mean()
                    c_mean = cluster_data['Contaminaci√≥n (%)'].mean()
                    st.success(f"**Grupo {i}**\n- Precisi√≥n: {p_mean:.1f}%\n- Contam.: {c_mean:.1f}%")
        else:
            st.warning("Datos insuficientes para Clustering (>10 registros requeridos).")

    # ==========================================
    # TAB 4: PREDICCIONES (REGRESI√ìN LINEAL - 30 D√çAS)
    # ==========================================
    with tab4:
        st.subheader("üîÆ Proyecci√≥n Mensual de Demanda (30 D√≠as)")
        st.markdown("Modelo de **Regresi√≥n Lineal** para estimar el volumen de carga del pr√≥ximo mes calendario.")

        # Agrupar datos por d√≠a
        daily_vol = df.groupby('Fecha Ingreso')['Vol. IA (m¬≥)'].sum().reset_index()
        
        if len(daily_vol) > 5:
            # Ingenier√≠a de Caracter√≠sticas
            daily_vol['Dia_Num'] = (daily_vol['Fecha Ingreso'] - daily_vol['Fecha Ingreso'].min()).dt.days
            
            # Entrenamiento
            X_reg = daily_vol[['Dia_Num']]
            y_reg = daily_vol['Vol. IA (m¬≥)']
            model = LinearRegression()
            model.fit(X_reg, y_reg)
            
            # --- PREDICCI√ìN EXTENDIDA (30 D√çAS) ---
            last_day_num = daily_vol['Dia_Num'].max()
            # Creamos un rango de 1 a 30 d√≠as en el futuro
            future_days_num = np.array(range(last_day_num + 1, last_day_num + 31)).reshape(-1, 1)
            future_vol = model.predict(future_days_num)
            
            # Fechas futuras (30 d√≠as)
            last_date = daily_vol['Fecha Ingreso'].max()
            future_dates = [last_date + datetime.timedelta(days=i) for i in range(1, 31)]
            
            # DataFrame Futuro
            df_future = pd.DataFrame({
                'Fecha Ingreso': future_dates,
                'Vol. IA (m¬≥)': future_vol,
                'Tipo': 'Proyecci√≥n (30 D√≠as)'
            })
            daily_vol['Tipo'] = 'Hist√≥rico Real'
            
            # Unir datasets
            df_combined = pd.concat([daily_vol, df_future])

            # M√©tricas de la Proyecci√≥n
            vol_proyectado_mes = df_future['Vol. IA (m¬≥)'].sum()
            tendencia_txt = "Creciente" if model.coef_[0] > 0 else "Decreciente"

            col_p1, col_p2 = st.columns(2)
            col_p1.metric("Volumen Total Estimado (30 d√≠as)", f"{vol_proyectado_mes:,.0f} m¬≥")
            col_p2.metric("Tendencia de Carga", tendencia_txt, f"{model.coef_[0]:.2f} m¬≥/d√≠a")

            # Visualizaci√≥n
            fig_pred, ax_p = plt.subplots(figsize=(12, 5))
            
            # Graficar Hist√≥rico vs Predicci√≥n
            sns.lineplot(









